[Unit]
Description=vLLM container service
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
Environment=PATH=/usr/bin:/bin
TimeoutStartSec=1200
TimeoutStopSec=120
ExecStartPre=docker volume create {{ vllm_volume_name }}
ExecStartPre=-docker rm --force {{ vllm_container_name }}
ExecStartPre=docker pull {{ vllm_docker_image }}
ExecStart=docker run \
  --name={{ vllm_container_name }} \
  --publish={{ vllm_port }}:8000 \
  --volume={{ vllm_volume_name }}:{{ vllm_volume_mount }} \
  --gpus {{ vllm_gpu_devices }} \
  --ipc=host \
  --env=HUGGING_FACE_HUB_TOKEN={{ hugging_face_token }} \
  --detach=false \
  {{ vllm_docker_image }} \
    --model={{ vllm_model }} \
    --max-model-len={{ vllm_max_model_len }} \
    --gpu-memory-utilization={{ vllm_gpu_memory_utilization }} \
    --tensor-parallel-size={{ vllm_tensor_parallel_size }} \
    --enable-auto-tool-choice \
    --tool-call-parser={{ vllm_tool_call_parser }}
ExecStop=docker stop {{ vllm_container_name }}
Restart=always
RestartSec=30

[Install]
WantedBy=multi-user.target
