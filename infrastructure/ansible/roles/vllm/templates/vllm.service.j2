[Unit]
Description=vLLM container service
Wants=network-online.target
After=network-online.target docker.service
Requires=docker.service

[Service]
Type=simple
TimeoutStartSec=1200
TimeoutStopSec=120
ExecStartPre=/usr/bin/docker volume create {{ vllm_volume_name }}
ExecStartPre=-/usr/bin/docker rm --force {{ vllm_container_name }}
ExecStart=/usr/bin/docker run \
  --name={{ vllm_container_name }} \
  --publish={{ vllm_port }}:8000 \
  --volume={{ vllm_volume_name }}:{{ vllm_volume_mount }} \
  --gpus {{ vllm_gpu_devices }} \
  --ipc=host \
  --env=HUGGING_FACE_HUB_TOKEN={{ vllm_hugging_face_token }} \
  --detach=false \
  {{ vllm_docker_image }} \
    --model={{ vllm_model }} \
    --max-model-len={{ vllm_max_model_len }} \
    --gpu-memory-utilization={{ vllm_gpu_memory_utilization }} \
    --tensor-parallel-size={{ vllm_tensor_parallel_size }} \
    --enable-auto-tool-choice \
    --tool-call-parser={{ vllm_tool_call_parser }}
ExecStop=/usr/bin/docker stop {{ vllm_container_name }}
Restart=always
RestartSec=30

[Install]
WantedBy=multi-user.target
